# Client HTTP Asynchrone R√©silient

Client HTTP asynchrone avanc√© avec strat√©gie de retry intelligente, gestion d'√©v√©nements par queue asynchrone et contextes isol√©s par coroutine.

## üöÄ Fonctionnalit√©s Principales

- **Architecture Asynchrone** : Bas√© sur `httpx.AsyncClient` avec support complet d'asyncio
- **Strat√©gie de Retry Intelligente** : Retry automatique sur `httpcore.ConnectError` uniquement
- **Contextes Isol√©s** : Chaque coroutine poss√®de son propre contexte clonable
- **Communication par √âv√©nements** : Queue asynchrone pour monitoring centralis√©
- **Types Complets** : Annotations de type exhaustives avec `Final` pour les constantes
- **Backoff Exponentiel** : D√©lais intelligents avec jitter anti-thundering herd
- **Monitoring Int√©gr√©** : Callbacks d'√©v√©nements et m√©triques en temps r√©el

## üì¶ Installation

```bash
# Installation de base
pip install httpx pytest pytest-asyncio

# Installation avec HTTP/2
pip install httpx[http2]

# Installation compl√®te pour d√©veloppement
pip install httpx[http2] pytest pytest-asyncio pytest-cov mypy black isort
```

## üèóÔ∏è Architecture

### Composants Principaux

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RequestContext    ‚îÇ    ‚îÇ    AsyncEvent       ‚îÇ    ‚îÇ   RequestResult     ‚îÇ
‚îÇ   (Immutable)       ‚îÇ    ‚îÇ   (Communication)   ‚îÇ    ‚îÇ   (Final State)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ max_retries       ‚îÇ    ‚îÇ ‚Ä¢ event_type        ‚îÇ    ‚îÇ ‚Ä¢ request_id        ‚îÇ
‚îÇ ‚Ä¢ current_attempt   ‚îÇ    ‚îÇ ‚Ä¢ context           ‚îÇ    ‚îÇ ‚Ä¢ status            ‚îÇ
‚îÇ ‚Ä¢ base_delay        ‚îÇ    ‚îÇ ‚Ä¢ timestamp         ‚îÇ    ‚îÇ ‚Ä¢ response          ‚îÇ
‚îÇ ‚Ä¢ request_id        ‚îÇ    ‚îÇ ‚Ä¢ data/error        ‚îÇ    ‚îÇ ‚Ä¢ attempts          ‚îÇ
‚îÇ ‚Ä¢ metadata          ‚îÇ    ‚îÇ ‚Ä¢ metadata          ‚îÇ    ‚îÇ ‚Ä¢ total_time        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                           ‚îÇ                           ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ            AsyncResilientClient                             ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ ‚Ä¢ httpx.AsyncClient wrapper                                 ‚îÇ
         ‚îÇ ‚Ä¢ asyncio.Queue pour √©v√©nements                             ‚îÇ
         ‚îÇ ‚Ä¢ Event loop monitoring                                     ‚îÇ
         ‚îÇ ‚Ä¢ Gestion des t√¢ches concurrentes                           ‚îÇ
         ‚îÇ ‚Ä¢ Callbacks d'√©v√©nements                                    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flow d'Ex√©cution

```
1. Cr√©ation du contexte (RequestContext)
2. Lancement de la coroutine de requ√™te
3. Tentative de connexion HTTP
4. En cas d'erreur ConnectError :
   ‚îú‚îÄ Incr√©ment du contexte
   ‚îú‚îÄ V√©rification des retries restants
   ‚îú‚îÄ Calcul du d√©lai (backoff + jitter)
   ‚îú‚îÄ √âmission d'√©v√©nement RETRY
   ‚îî‚îÄ Nouvelle tentative
5. Succ√®s ou √©chec d√©finitif :
   ‚îú‚îÄ √âmission d'√©v√©nement SUCCESS/ERROR
   ‚îú‚îÄ Stockage du r√©sultat
   ‚îî‚îÄ Appel des callbacks
```

## üìñ Guide d'Utilisation

### 1. Utilisation Simple

```python
import asyncio
from typed_async_client import simple_async_request

async def exemple_simple():
    try:
        # Requ√™te GET avec retry automatique
        response = await simple_async_request(
            "GET",
            "https://api.example.com/data",
            max_retries=2,
            timeout=10.0
        )
        
        print(f"‚úÖ Succ√®s: {response.status_code}")
        data = response.json()
        return data
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return None

# Lancement
result = asyncio.run(exemple_simple())
```

### 2. Client Avanc√© avec Context Manager

```python
import asyncio
from typed_async_client import (
    create_async_resilient_client, 
    RequestContext, 
    EventType
)

async def exemple_avance():
    # Callbacks pour monitoring
    async def on_retry(event):
        print(f"üîÑ Retry: {event.context.request_id} "
              f"(tentative {event.context.current_attempt})")
    
    async def on_error(event):
        print(f"‚ùå Erreur: {event.context.request_id} - {event.error}")
    
    # Configuration du client
    async with create_async_resilient_client(
        timeout=httpx.Timeout(connect=5.0, read=30.0),
        limits=httpx.Limits(max_connections=50),
        event_queue_size=100
    ) as client:
        
        # Ajouter les callbacks
        client.add_event_callback(EventType.RETRY, on_retry)
        client.add_event_callback(EventType.ERROR, on_error)
        
        # Contexte personnalis√©
        context = RequestContext(
            max_retries=3,
            base_delay=0.5,
            request_id="api_data_fetch",
            metadata={"priority": "high"}
        )
        
        # Lancer la requ√™te
        task = await client.get(
            "https://api.example.com/data",
            context=context,
            headers={"Authorization": "Bearer YOUR_TOKEN"}
        )
        
        # Attendre le r√©sultat
        response = await task
        print(f"Status: {response.status_code}")
        
        # R√©cup√©rer les m√©triques
        result = client.get_result("api_data_fetch")
        print(f"Tentatives: {result.attempts}")
        print(f"Temps total: {result.total_time:.2f}s")

asyncio.run(exemple_avance())
```

### 3. Requ√™tes Concurrentes

```python
import asyncio
from typed_async_client import create_async_resilient_client, RequestContext

async def requetes_concurrentes():
    urls_et_contextes = [
        ("https://api.service1.com/users", 
         RequestContext(request_id="users", max_retries=2)),
        ("https://api.service2.com/posts", 
         RequestContext(request_id="posts", max_retries=3)),
        ("https://api.service3.com/comments", 
         RequestContext(request_id="comments", max_retries=1)),
    ]
    
    async with create_async_resilient_client() as client:
        # Lancer toutes les requ√™tes en parall√®le
        tasks = []
        for url, context in urls_et_contextes:
            task = await client.get(url, context=context)
            tasks.append(task)
        
        # Attendre toutes les r√©ponses
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Analyser les r√©sultats
        results = await client.wait_for_all_requests()
        
        for request_id, result in results.items():
            status = "‚úÖ" if result.is_success else "‚ùå"
            print(f"{status} {request_id}: {result.status} "
                  f"({result.attempts} tentatives)")

asyncio.run(requetes_concurrentes())
```

### 4. Int√©gration avec FastAPI

```python
from fastapi import FastAPI, HTTPException
from typed_async_client import create_async_resilient_client, RequestContext

app = FastAPI()

# Client global (√† initialiser au d√©marrage)
http_client = None

@app.on_event("startup")
async def startup():
    global http_client
    http_client = AsyncResilientClient()
    await http_client._initialize_client()

@app.on_event("shutdown")
async def shutdown():
    global http_client
    if http_client:
        await http_client.close()

@app.get("/api/external-data/{data_id}")
async def get_external_data(data_id: str):
    context = RequestContext(
        request_id=f"external_data_{data_id}",
        max_retries=2
    )
    
    try:
        task = await http_client.get(
            f"https://external-api.com/data/{data_id}",
            context=context
        )
        response = await task
        
        if response.status_code == 200:
            return response.json()
        else:
            raise HTTPException(
                status_code=response.status_code,
                detail="Erreur API externe"
            )
            
    except Exception as e:
        # R√©cup√©rer les m√©triques pour logging
        result = http_client.get_result(context.request_id)
        if result:
            print(f"√âchec apr√®s {result.attempts} tentatives")
        
        raise HTTPException(
            status_code=503,
            detail="Service externe indisponible"
        )
```

## üîß Configuration Avanc√©e

### Constantes Personnalis√©es

```python
# async_client_constants.py
from typing import Final

# Valeurs personnalis√©es pour votre application
CUSTOM_MAX_RETRIES: Final[int] = 5
CUSTOM_BASE_DELAY: Final[float] = 0.5
CUSTOM_BACKOFF_FACTOR: Final[float] = 1.5

# Headers sp√©cialis√©s
API_HEADERS: Final[dict[str, str]] = {
    "User-Agent": "MonApp/2.0",
    "Accept": "application/json",
    "X-API-Version": "v2"
}
```

### Contexte Personnalis√©

```python
from dataclasses import dataclass
from typed_async_client import RequestContext

@dataclass(frozen=True)
class ApiRequestContext(RequestContext):
    """Contexte √©tendu pour API sp√©cialis√©e."""
    api_version: str = "v1"
    priority: str = "normal"
    trace_id: str = ""
    
    def to_headers(self) -> dict[str, str]:
        """Convertit le contexte en headers HTTP."""
        return {
            "X-API-Version": self.api_version,
            "X-Priority": self.priority,
            "X-Trace-ID": self.trace_id or self.request_id
        }

# Utilisation
context = ApiRequestContext(
    request_id="custom_api_call",
    max_retries=3,
    api_version="v2",
    priority="high",
    trace_id="trace_12345"
)

async with create_async_resilient_client() as client:
    task = await client.get(
        "https://api.example.com/data",
        context=context,
        headers=context.to_headers()
    )
    response = await task
```

## üß™ Tests et Validation

### Structure des Tests

```
tests/
‚îú‚îÄ‚îÄ test_context.py          # Tests des contextes
‚îú‚îÄ‚îÄ test_events.py           # Tests des √©v√©nements
‚îú‚îÄ‚îÄ test_client.py           # Tests du client principal
‚îú‚îÄ‚îÄ test_retry_logic.py      # Tests de la logique de retry
‚îú‚îÄ‚îÄ test_concurrent.py       # Tests de concurrence
‚îú‚îÄ‚îÄ test_integration.py      # Tests d'int√©gration
‚îî‚îÄ‚îÄ conftest.py             # Configuration pytest
```

### Lancement des Tests

```bash
# Tests unitaires seulement
pytest tests/ -v -m "not integration"

# Tests avec couverture
pytest tests/ --cov=typed_async_client --cov-report=html

# Tests d'int√©gration (n√©cessite internet)
pytest tests/ -v -m integration

# Tests de performance
pytest tests/ -v -m slow --durations=10

# Tests en parall√®le
pytest tests/ -n auto
```

### Exemple de Test Personnalis√©

```python
import pytest
import asyncio
from unittest.mock import AsyncMock, patch
from typed_async_client import AsyncResilientClient, RequestContext

class TestCustomScenario:
    @pytest.mark.asyncio
    async def test_custom_retry_scenario(self):
        """Test d'un sc√©nario m√©tier sp√©cifique."""
        async with AsyncResilientClient() as client:
            context = RequestContext(
                request_id="business_critical",
                max_retries=5,
                base_delay=0.1
            )
            
            with patch.object(client._client, 'request') as mock:
                # Simuler 3 √©checs puis 1 succ√®s
                mock_response = AsyncMock()
                mock_response.status_code = 200
                
                mock.side_effect = [
                    httpcore.ConnectError("Fail 1"),
                    httpcore.ConnectError("Fail 2"), 
                    httpcore.ConnectError("Fail 3"),
                    mock_response
                ]
                
                task = await client.get("https://test.com", context=context)
                response = await task
                
                assert response.status_code == 200
                assert mock.call_count == 4
                
                # V√©rifier les m√©triques
                result = client.get_result("business_critical")
                assert result.attempts == 4
                assert result.is_success
```

## üìä Monitoring et M√©triques

### Callbacks d'√âv√©nements

```python
import logging
from collections import defaultdict
from typing import Dict

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MetricsCollector:
    def __init__(self):
        self.stats: Dict[str, int] = defaultdict(int)
        self.response_times: list[float] = []
    
    async def on_success(self, event):
        self.stats['success'] += 1
        self.response_times.append(event.context.elapsed_time)
        logger.info(f"‚úÖ Succ√®s: {event.context.request_id}")
    
    async def on_retry(self, event):
        self.stats['retry'] += 1
        logger.warning(f"üîÑ Retry {event.context.current_attempt}: "
                      f"{event.context.request_id}")
    
    async def on_error(self, event):
        self.stats['error'] += 1
        logger.error(f"‚ùå Erreur d√©finitive: {event.context.request_id}")
    
    def get_metrics(self) -> dict:
        total = sum(self.stats.values())
        if total == 0:
            return {}
        
        avg_response_time = (
            sum(self.response_times) / len(self.response_times)
            if self.response_times else 0
        )
        
        return {
            'total_requests': total,
            'success_rate': self.stats['success'] / total,
            'retry_rate': self.stats['retry'] / total,
            'error_rate': self.stats['error'] / total,
            'avg_response_time': avg_response_time
        }

# Utilisation
async def monitored_requests():
    metrics = MetricsCollector()
    
    async with create_async_resilient_client() as client:
        # Ajouter les callbacks de monitoring
        client.add_event_callback(EventType.SUCCESS, metrics.on_success)
        client.add_event_callback(EventType.RETRY, metrics.on_retry)
        client.add_event_callback(EventType.ERROR, metrics.on_error)
        
        # Faire plusieurs requ√™tes
        urls = ["https://httpbin.org/get" for _ in range(10)]
        tasks = []
        
        for i, url in enumerate(urls):
            context = RequestContext(request_id=f"req_{i}")
            task = await client.get(url, context=context)
            tasks.append(task)
        
        # Attendre toutes les requ√™tes
        await asyncio.gather(*tasks, return_exceptions=True)
        await client.wait_for_all_requests()
        
        # Afficher les m√©triques
        stats = metrics.get_metrics()
        print("üìä M√©triques:")
        for key, value in stats.items():
            print(f"  {key}: {value}")

asyncio.run(monitored_requests())
```

### Dashboard en Temps R√©el

```python
import asyncio
import time
from datetime import datetime

class RealTimeDashboard:
    def __init__(self, client: AsyncResilientClient):
        self.client = client
        self.running = False
    
    async def start_monitoring(self):
        """D√©marre le monitoring en temps r√©el."""
        self.running = True
        while self.running:
            await self.display_stats()
            await asyncio.sleep(5)  # Actualisation toutes les 5s
    
    async def display_stats(self):
        """Affiche les statistiques actuelles."""
        print(f"\n{'='*50}")
        print(f"üöÄ Dashboard - {datetime.now().strftime('%H:%M:%S')}")
        print(f"{'='*50}")
        print(f"T√¢ches actives: {self.client.active_tasks_count}")
        print(f"R√©sultats en cache: {self.client.results_count}")
        print(f"Queue d'√©v√©nements: {self.client.event_queue_size}")
        print(f"Client ferm√©: {self.client.is_closed}")
        
        # Statistiques des r√©sultats
        results = self.client.get_all_results()
        if results:
            success_count = sum(1 for r in results.values() if r.is_success)
            error_count = sum(1 for r in results.values() if r.is_error)
            avg_attempts = sum(r.attempts for r in results.values()) / len(results)
            
            print(f"Succ√®s: {success_count}/{len(results)}")
            print(f"Erreurs: {error_count}/{len(results)}")
            print(f"Tentatives moyennes: {avg_attempts:.1f}")
    
    def stop(self):
        """Arr√™te le monitoring."""
        self.running = False

# Utilisation avec le dashboard
async def exemple_avec_dashboard():
    async with create_async_resilient_client() as client:
        dashboard = RealTimeDashboard(client)
        
        # D√©marrer le monitoring en arri√®re-plan
        monitor_task = asyncio.create_task(dashboard.start_monitoring())
        
        try:
            # Lancer des requ√™tes
            tasks = []
            for i in range(20):
                context = RequestContext(request_id=f"dashboard_req_{i}")
                task = await client.get(
                    f"https://httpbin.org/delay/{i%3}",  # D√©lais variables
                    context=context
                )
                tasks.append(task)
                await asyncio.sleep(0.5)  # Espacement des requ√™tes
            
            # Attendre toutes les requ√™tes
            await asyncio.gather(*tasks, return_exceptions=True)
            
        finally:
            dashboard.stop()
            await monitor_task

# asyncio.run(exemple_avec_dashboard())
```

## üõ†Ô∏è D√©pannage et Bonnes Pratiques

### Probl√®mes Courants

#### 1. Timeout de Queue d'√âv√©nements

```python
# ‚ùå Probl√®me : Queue satur√©e
client = AsyncResilientClient(event_queue_size=10)  # Trop petit

# ‚úÖ Solution : Augmenter la taille
client = AsyncResilientClient(event_queue_size=1000)
```

#### 2. Fuites de M√©moire

```python
# ‚ùå Probl√®me : R√©sultats qui s'accumulent
# Les r√©sultats ne sont jamais nettoy√©s

# ‚úÖ Solution : Nettoyage p√©riodique
async def cleanup_task(client):
    while not client.is_closed:
        await asyncio.sleep(300)  # Toutes les 5 minutes
        cleaned = client.clear_old_results(max_age=3600)  # 1 heure
        if cleaned > 0:
            print(f"üßπ Nettoy√© {cleaned} anciens r√©sultats")
```

#### 3. Trop de T√¢ches Concurrentes

```python
# ‚ùå Probl√®me : Lancement de trop de t√¢ches
for i in range(10000):  # Trop !
    task = await client.get(f"https://api.com/{i}")

# ‚úÖ Solution : Limitation avec semaphore
semaphore = asyncio.Semaphore(50)  # Max 50 concurrent

async def limited_request(client, url, context):
    async with semaphore:
        task = await client.get(url, context=context)
        return await task
```

### Optimisations de Performance

#### 1. R√©utilisation du Client

```python
# ‚ùå Mauvais : Nouveau client √† chaque fois
async def bad_example():
    async with create_async_resilient_client() as client:
        task = await client.get("https://api.com/data")
        return await task

# ‚úÖ Bon : Client r√©utilis√©
class ApiService:
    def __init__(self):
        self.client = None
    
    async def __aenter__(self):
        self.client = AsyncResilientClient()
        await self.client._initialize_client()
        return self
    
    async def __aexit__(self, *args):
        if self.client:
            await self.client.close()
    
    async def get_data(self, endpoint: str):
        context = RequestContext(request_id=f"api_{endpoint}")
        task = await self.client.get(f"https://api.com/{endpoint}", context=context)
        return await task
```

#### 2. Configuration Optimale

```python
# Configuration pour haute performance
optimal_client = AsyncResilientClient(
    timeout=httpx.Timeout(
        connect=5.0,    # Connexion rapide
        read=30.0,      # Lecture g√©n√©reuse
        write=10.0,     # √âcriture mod√©r√©e
        pool=5.0        # Pool rapide
    ),
    limits=httpx.Limits(
        max_connections=100,        # Beaucoup de connexions
        max_keepalive_connections=50  # Keep-alive √©lev√©
    ),
    event_queue_size=5000,  # Queue g√©n√©reuse
    headers={
        "Connection": "keep-alive",
        "Keep-Alive": "timeout=30, max=100"
    }
)
```

## üìö R√©f√©rences et Ressources

### Documentation Technique

- [HTTPX Documentation](https://www.python-httpx.org/)
- [AsyncIO Official Guide](https://docs.python.org/3/library/asyncio.html)
- [Python Type Hints](https://docs.python.org/3/library/typing.html)

### Exemples Complets

Consultez le dossier `examples/` pour des cas d'usage complets :

- `basic_usage.py` - Utilisation de base
- `fastapi_integration.py` - Int√©gration FastAPI
- `monitoring_example.py` - Monitoring avanc√©
- `load_testing.py` - Tests de charge
- `error_handling.py` - Gestion d'erreurs

### Performance et Benchmarks

```bash
# Lancer les benchmarks
python examples/benchmark.py

# R√©sultats typiques (sur machine standard) :
# ‚úÖ 1000 requ√™tes concurrentes : 45.2s
# ‚úÖ Taux de succ√®s : 98.5%
# ‚úÖ Retry rate : 12.3%
# ‚úÖ M√©moire utilis√©e : 125 MB
```

---

## üìÑ License

MIT License - voir le fichier `LICENSE` pour plus de d√©tails.

## ü§ù Contribution

Les contributions sont les bienvenues ! Voir `CONTRIBUTING.md` pour les guidelines.